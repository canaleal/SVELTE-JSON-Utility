{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "Here we will load all the traffic data from the data directory and visualize/ describe the amount of data available, and the type of columns/ rows we are working with. Ensure there are no hard coded strings, or variables as there is a possibility we might gain access to more traffic volume data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "DATA_FOLDER_PATH = '../data/'\n",
    "\n",
    "def get_all_files(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def load_csv_data(path, file_name):\n",
    "    return pd.read_csv(path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>count_id</th>\n",
       "      <th>count_date</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>centreline_type</th>\n",
       "      <th>centreline_id</th>\n",
       "      <th>px</th>\n",
       "      <th>...</th>\n",
       "      <th>ex_peds</th>\n",
       "      <th>wx_peds</th>\n",
       "      <th>nx_bike</th>\n",
       "      <th>sx_bike</th>\n",
       "      <th>ex_bike</th>\n",
       "      <th>wx_bike</th>\n",
       "      <th>nx_other</th>\n",
       "      <th>sx_other</th>\n",
       "      <th>ex_other</th>\n",
       "      <th>wx_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8180</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4126</td>\n",
       "      <td>EGLINTON AVE AT PHARMACY AVE (PX 452)</td>\n",
       "      <td>-79.297515</td>\n",
       "      <td>43.725651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13453978.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8180</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4126</td>\n",
       "      <td>EGLINTON AVE AT PHARMACY AVE (PX 452)</td>\n",
       "      <td>-79.297515</td>\n",
       "      <td>43.725651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13453978.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8180</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4126</td>\n",
       "      <td>EGLINTON AVE AT PHARMACY AVE (PX 452)</td>\n",
       "      <td>-79.297515</td>\n",
       "      <td>43.725651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13453978.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8180</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4126</td>\n",
       "      <td>EGLINTON AVE AT PHARMACY AVE (PX 452)</td>\n",
       "      <td>-79.297515</td>\n",
       "      <td>43.725651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13453978.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8180</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>4126</td>\n",
       "      <td>EGLINTON AVE AT PHARMACY AVE (PX 452)</td>\n",
       "      <td>-79.297515</td>\n",
       "      <td>43.725651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13453978.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  count_id  count_date  location_id   \n",
       "0    1      8180  2000-01-18         4126  \\\n",
       "1    2      8180  2000-01-18         4126   \n",
       "2    3      8180  2000-01-18         4126   \n",
       "3    4      8180  2000-01-18         4126   \n",
       "4    5      8180  2000-01-18         4126   \n",
       "\n",
       "                                location        lng        lat   \n",
       "0  EGLINTON AVE AT PHARMACY AVE (PX 452) -79.297515  43.725651  \\\n",
       "1  EGLINTON AVE AT PHARMACY AVE (PX 452) -79.297515  43.725651   \n",
       "2  EGLINTON AVE AT PHARMACY AVE (PX 452) -79.297515  43.725651   \n",
       "3  EGLINTON AVE AT PHARMACY AVE (PX 452) -79.297515  43.725651   \n",
       "4  EGLINTON AVE AT PHARMACY AVE (PX 452) -79.297515  43.725651   \n",
       "\n",
       "   centreline_type  centreline_id     px  ... ex_peds wx_peds  nx_bike   \n",
       "0              2.0     13453978.0  452.0  ...     7.0    17.0      0.0  \\\n",
       "1              2.0     13453978.0  452.0  ...    12.0     4.0      1.0   \n",
       "2              2.0     13453978.0  452.0  ...     7.0     3.0      0.0   \n",
       "3              2.0     13453978.0  452.0  ...     9.0     4.0      0.0   \n",
       "4              2.0     13453978.0  452.0  ...    10.0     4.0      3.0   \n",
       "\n",
       "   sx_bike  ex_bike  wx_bike  nx_other  sx_other  ex_other  wx_other  \n",
       "0      0.0      0.0      0.0       0.0       0.0       0.0       0.0  \n",
       "1      0.0      0.0      0.0       0.0       0.0       0.0       0.0  \n",
       "2      0.0      0.0      0.0       0.0       0.0       0.0       0.0  \n",
       "3      0.0      0.0      0.0       0.0       0.0       0.0       0.0  \n",
       "4      0.0      3.0      0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV Data into DF from folder\n",
    "all_files = get_all_files(DATA_FOLDER_PATH)\n",
    "all_df = [load_csv_data(DATA_FOLDER_PATH, file_name) for file_name in all_files]\n",
    "all_df[0].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection & Assessment\n",
    "\n",
    "1. **Merge the Data**: Merge all the data frames from `all_df` into a single data frame instead.\n",
    "\n",
    "2. **Inspect the Data Structure**: Look at the overall structure of the dataframe using `.info()` to understand the data types, number of entries, etc.\n",
    "\n",
    "3. **Summary Statistics**: Generate descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset's distribution using `.describe()`.\n",
    "\n",
    "4. **Investigate Null Values**: Count the number of null values in each column using `isnull().sum()` to understand the quality of the data.\n",
    "\n",
    "5. **Understand Unique Values**: For categorical columns, use `.unique()` or `.nunique()` to understand how many unique categories each column has.\n",
    "\n",
    "6. **Explore Relationships**: Look at the correlation matrix between numerical columns using `.corr()` to get an initial understanding of the relationships.\n",
    "\n",
    "7. **Visualize Data Distributions**: Plot histograms or bar plots to understand the distribution of your data for each variable.\n",
    "\n",
    "8. **Visualize Pairwise Relationships**: Use pair plots or scatter plots to understand potential relationships or trends within pairs of variables.\n",
    "\n",
    "9. **Temporal Patterns (if applicable)**: If your data has a time component, plot the variables over time to observe any apparent trends or seasonality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Transformation\n",
    "\n",
    "Here we focus on cleaning our traffic volume dataset. The main steps we will undertake are:\n",
    "\n",
    "1. **Handling Missing Values:** We'll identify and impute missing values based on an appropriate strategy, or remove them if necessary.\n",
    "\n",
    "2. **Outlier Detection and Handling:** We will use statistical techniques to detect any outliers present in our dataset and manage them appropriately.\n",
    "\n",
    "3. **Data Type Conversion:** For more effective analysis, we'll adjust data types, such as converting timestamps to a format that is more suitable for time series analysis.\n",
    "\n",
    "4. **Data Normalization:** We'll adjust the traffic data where required. This could involve converting raw counts to traffic volume per hour, adjusting for the number of lanes, or scaling the data to a standard range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
